{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os, time, re\n",
    "\n",
    "from audio_utils import AudioRecorder, SpeechRecognizer, TextToAudioConverter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, os\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers.modeling_tf_distilbert import TFDistilBertModel\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to run RPA?</td>\n",
       "      <td>1</td>\n",
       "      <td>rpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you run RPA?</td>\n",
       "      <td>1</td>\n",
       "      <td>rpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Call RPA please?</td>\n",
       "      <td>1</td>\n",
       "      <td>rpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Write email?</td>\n",
       "      <td>1</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Could you send email?</td>\n",
       "      <td>1</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Could you book a hotel for me?</td>\n",
       "      <td>1</td>\n",
       "      <td>hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Could you run RPA?</td>\n",
       "      <td>1</td>\n",
       "      <td>rpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I would like to listen some music</td>\n",
       "      <td>1</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Could you play some music?</td>\n",
       "      <td>1</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Open calendar please</td>\n",
       "      <td>0</td>\n",
       "      <td>calendar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What's that?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What time is it?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>May I open the window?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Is there a bakery near here?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Where is the nearest bank?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Who wrote this article?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Is there any rice?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Are there any sandwiches?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Is this your book?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Whose is that?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What do you like to do on weekends?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What does she look like?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What would you like to eat?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What is it like?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What's the weather like?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Would you like some coffee?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Would you like something to drink?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What's it about?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What do you think about this book?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Is it difficult to prepare for IELTS?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What are your views on Donald Trump as the Ame...</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>How was the movie?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>How do you feel about Clara?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>How about some lunch?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Hi there, how are you?</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  label1    label2\n",
       "0                                     How to run RPA?       1       rpa\n",
       "1                                  Could you run RPA?       1       rpa\n",
       "2                                    Call RPA please?       1       rpa\n",
       "3                                        Write email?       1     email\n",
       "4                               Could you send email?       1     email\n",
       "5                      Could you book a hotel for me?       1     hotel\n",
       "6                                  Could you run RPA?       1       rpa\n",
       "7                   I would like to listen some music       1     music\n",
       "8                          Could you play some music?       1     music\n",
       "9                                Open calendar please       0  calendar\n",
       "10                                       What's that?       0    others\n",
       "11                                   What time is it?       0    others\n",
       "12                             May I open the window?       0    others\n",
       "13                       Is there a bakery near here?       0    others\n",
       "14                         Where is the nearest bank?       0    others\n",
       "15                            Who wrote this article?       0    others\n",
       "16                                 Is there any rice?       0    others\n",
       "17                          Are there any sandwiches?       0    others\n",
       "18                                 Is this your book?       0    others\n",
       "19                                     Whose is that?       0    others\n",
       "20                What do you like to do on weekends?       0    others\n",
       "21                           What does she look like?       0    others\n",
       "22                        What would you like to eat?       0    others\n",
       "23                                   What is it like?       0    others\n",
       "24                           What's the weather like?       0    others\n",
       "25                        Would you like some coffee?       0    others\n",
       "26                 Would you like something to drink?       0    others\n",
       "27                                   What's it about?       0    others\n",
       "28                 What do you think about this book?       0    others\n",
       "29              Is it difficult to prepare for IELTS?       0    others\n",
       "30  What are your views on Donald Trump as the Ame...       0    others\n",
       "31                                 How was the movie?       0    others\n",
       "32                       How do you feel about Clara?       0    others\n",
       "33                              How about some lunch?       0    others\n",
       "34                             Hi there, how are you?       0    others"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\", delimiter=\",\")\n",
    "label = data[\"label1\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    text.fillna(\"fillna\").str.lower()\n",
    "    text = text.map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
    "    text = text.map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
    "    text = text.str.replace(\"?\",\"\").str.replace(\"'\",\" \").str.lower()\n",
    "    # Unimportant part\n",
    "    text = text.map(lambda x: re.sub(\"(could|please|would|may)\",'',str(x)))\n",
    "    text = text.map(lambda x: re.sub(r\"\\b(\"+r\"|\".join(stopwords.words(\"english\"))+r\")\\b\",'',str(x)))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run rpa</td>\n",
       "      <td>1</td>\n",
       "      <td>rpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run rpa</td>\n",
       "      <td>1</td>\n",
       "      <td>rpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>call rpa</td>\n",
       "      <td>1</td>\n",
       "      <td>rpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>write email</td>\n",
       "      <td>1</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>send email</td>\n",
       "      <td>1</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>book  hotel</td>\n",
       "      <td>1</td>\n",
       "      <td>hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>run rpa</td>\n",
       "      <td>1</td>\n",
       "      <td>rpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>like  listen  music</td>\n",
       "      <td>1</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>play  music</td>\n",
       "      <td>1</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>open calendar</td>\n",
       "      <td>0</td>\n",
       "      <td>calendar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>time</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>open  window</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bakery near</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nearest bank</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wrote  article</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rice</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sandwiches</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>book</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>whose</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>like    weekends</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>look like</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>like  eat</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>like</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>weather like</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>like  coffee</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>like something  drink</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>think   book</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>difficult  prepare  ielts</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>views  donald trump   america’ president</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>movie</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>feel  clara</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lunch</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>hi ,</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Question  label1    label2\n",
       "0                                       run rpa       1       rpa\n",
       "1                                       run rpa       1       rpa\n",
       "2                                     call rpa        1       rpa\n",
       "3                                   write email       1     email\n",
       "4                                    send email       1     email\n",
       "5                                 book  hotel         1     hotel\n",
       "6                                       run rpa       1       rpa\n",
       "7                           like  listen  music       1     music\n",
       "8                                   play  music       1     music\n",
       "9                                open calendar        0  calendar\n",
       "10                                                    0    others\n",
       "11                                       time         0    others\n",
       "12                                 open  window       0    others\n",
       "13                                 bakery near        0    others\n",
       "14                                 nearest bank       0    others\n",
       "15                               wrote  article       0    others\n",
       "16                                         rice       0    others\n",
       "17                                   sandwiches       0    others\n",
       "18                                         book       0    others\n",
       "19                                      whose         0    others\n",
       "20                             like    weekends       0    others\n",
       "21                                    look like       0    others\n",
       "22                                    like  eat       0    others\n",
       "23                                         like       0    others\n",
       "24                                 weather like       0    others\n",
       "25                                 like  coffee       0    others\n",
       "26                        like something  drink       0    others\n",
       "27                                                    0    others\n",
       "28                                 think   book       0    others\n",
       "29                    difficult  prepare  ielts       0    others\n",
       "30     views  donald trump   america’ president       0    others\n",
       "31                                        movie       0    others\n",
       "32                                  feel  clara       0    others\n",
       "33                                        lunch       0    others\n",
       "34                                      hi ,          0    others"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Question\"]=clean(data[\"Question\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_encode(texts, tokenizer, chunk_size=240, maxlen=512):    \n",
    "    tokenizer.enable_truncation(max_length=maxlen)\n",
    "    try:\n",
    "        tokenizer.enable_padding(max_length=maxlen)\n",
    "    except TypeError:\n",
    "        tokenizer.enable_padding(length=maxlen)\n",
    "    all_ids = []\n",
    "    \n",
    "    for i in range(0, len(texts), chunk_size):\n",
    "        text_chunk = texts[i:i+chunk_size].tolist()\n",
    "        encs = tokenizer.encode_batch(text_chunk)\n",
    "        all_ids.extend([enc.ids for enc in encs])\n",
    "\n",
    "    \n",
    "    return np.array(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "\n",
    "save_path = 'distilbert_base_uncased/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "\n",
    "fast_tokenizer = BertWordPieceTokenizer('distilbert_base_uncased/vocab.txt', \n",
    "                                        lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=30\n",
    "x_train = fast_encode(data[\"Question\"].astype(str), \n",
    "                      fast_tokenizer, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train part one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vnn_model(transformer, max_len, num_classes=2):\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    \n",
    "    embed = transformer.weights[0].numpy()\n",
    "    embedding = tf.keras.layers.Embedding(np.shape(embed)[0], np.shape(embed)[1],\n",
    "                          input_length=max_len, weights=[embed],\n",
    "                          trainable=False)(input_word_ids)\n",
    "#     print(embedding.shape)\n",
    "    conc = K.sum(embedding, axis=2)\n",
    "    conc = tf.keras.layers.Dense(128, activation='relu')(conc)\n",
    "#     conc = tf.keras.layers.Dense(256, activation='relu')(conc)\n",
    "    conc = tf.keras.layers.Dense(64, activation='relu')(conc)\n",
    "    \n",
    "    conc = tf.keras.layers.Dense(num_classes, activation='softmax')(conc)\n",
    "    loss = \"categorical_crossentropy\"\n",
    "        \n",
    "    model = tf.keras.models.Model(inputs=input_word_ids, outputs=conc)\n",
    "    \n",
    "    model.compile(tf.keras.optimizers.Adam(lr=0.0007), \n",
    "                  loss=loss, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_layer_norm', 'vocab_transform', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 30, 768)           91812096  \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowO [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3968      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 91,824,450\n",
      "Trainable params: 12,354\n",
      "Non-trainable params: 91,812,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer_layer = TFDistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
    "model_vnn = build_vnn_model(transformer_layer, max_len=max_len)\n",
    "model_vnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9100 - accuracy: 0.5143\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0501 - accuracy: 0.7429\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7429\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.5143\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7971 - accuracy: 0.4571\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.8286\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8571\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8571\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8571\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.8571\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.8571\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8571\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.6857\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8286\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.8571\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6203 - accuracy: 0.7429\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.8000\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8571\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 971us/step - loss: 0.4376 - accuracy: 0.7714\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 982us/step - loss: 0.5370 - accuracy: 0.6857\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8571\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8571\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.7429\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.7429\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.8571\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8571\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8286\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.8571\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8571\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 970us/step - loss: 0.3706 - accuracy: 0.8286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff1e63b1dd8>"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded = data[\"label1\"]\n",
    "label = tf.keras.utils.to_categorical(y_encoded)\n",
    "model_vnn.fit(x_train, label, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32581374 0.6741862 ]\n",
      " [0.03763636 0.9623636 ]\n",
      " [0.5370296  0.4629704 ]\n",
      " [0.9583503  0.04164964]] [1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "text =[\"could you write an email please\",\n",
    "      \"could you run rpa\",\n",
    "      \"could you open the window please\",\n",
    "      \"hi there how are you?\"]\n",
    "text = clean(pd.Series(text))\n",
    "test = fast_encode(text, fast_tokenizer, maxlen=max_len)\n",
    "y_pred = model_vnn.predict(test)\n",
    "print(y_pred, y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      write  email \n",
       "1            run rpa\n",
       "2      open  window \n",
       "3             hi    \n",
       "dtype: object"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vnn.save(\"modelDNN1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff1a5a5ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[0.32581392 0.67418605]\n",
      " [0.03763631 0.9623637 ]\n",
      " [0.53702915 0.46297082]] [1 1 0]\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.models.load_model(\"modelDNN1.h5\")\n",
    "\n",
    "text =[\"could you write an email please\",\n",
    "      \"could you run rpa\",\n",
    "      \"could you open the window please\"]\n",
    "text = clean(pd.Series(text))\n",
    "test = fast_encode(text, fast_tokenizer, maxlen=max_len)\n",
    "y_pred = model1.predict(test)\n",
    "print(y_pred, y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Part two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 928us/step - loss: 3.2355 - accuracy: 0.2222\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 929us/step - loss: 1.5226 - accuracy: 0.4444\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 800us/step - loss: 1.6280 - accuracy: 0.5556\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5521 - accuracy: 0.5556\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 786us/step - loss: 1.3399 - accuracy: 0.5556\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0093 - accuracy: 0.5556\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 733us/step - loss: 0.7452 - accuracy: 0.6667\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 803us/step - loss: 0.7738 - accuracy: 0.7778\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8711 - accuracy: 0.6667\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 746us/step - loss: 0.7475 - accuracy: 0.7778\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 740us/step - loss: 0.5955 - accuracy: 0.8889\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 719us/step - loss: 0.5346 - accuracy: 0.8889\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7778\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 706us/step - loss: 0.5534 - accuracy: 0.6667\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 882us/step - loss: 0.5320 - accuracy: 0.6667\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 716us/step - loss: 0.4805 - accuracy: 0.8889\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8889\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 758us/step - loss: 0.3809 - accuracy: 0.7778\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 716us/step - loss: 0.3558 - accuracy: 0.7778\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8889\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 780us/step - loss: 0.3335 - accuracy: 0.8889\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 870us/step - loss: 0.3234 - accuracy: 0.8889\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3062 - accuracy: 0.8889\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2799 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2528 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 827us/step - loss: 0.2314 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 817us/step - loss: 0.2186 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 733us/step - loss: 0.2094 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 705us/step - loss: 0.2006 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 671us/step - loss: 0.1919 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff34fd65400>"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder2 = LabelEncoder()\n",
    "\n",
    "x_train2 = x_train[data[\"label1\"]==1]\n",
    "label = data[data[\"label1\"]==1][\"label2\"]\n",
    "y_encoded = labelencoder2.fit_transform(label)\n",
    "model_vnn2 = build_vnn_model(transformer_layer, max_len=max_len, num_classes=\n",
    "                             len(np.unique(y_encoded)))\n",
    "label = tf.keras.utils.to_categorical(y_encoded)\n",
    "model_vnn2.fit(x_train2, label, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['email', 'rpa'], dtype=object)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text =[\"could you send an email please\",\n",
    "      \"run rpa\"] \n",
    "text = clean(pd.Series(text))\n",
    "test = fast_encode(text, fast_tokenizer, maxlen=max_len)\n",
    "y_pred = model_vnn2.predict(test)\n",
    "labelencoder2.inverse_transform(y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vnn2.save(\"modelDNN2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labelencoder.pkl']"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(labelencoder2, \"labelencoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_n = joblib.load(\"labelencoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff2c6f6c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['email', 'rpa'], dtype=object)"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = tf.keras.models.load_model(\"modelDNN2.h5\")\n",
    "\n",
    "\n",
    "text =[\"could you send an email please\",\n",
    "      \"run rpa\"] \n",
    "text = clean(pd.Series(text))\n",
    "test = fast_encode(text, fast_tokenizer, maxlen=max_len)\n",
    "y_pred = model2.predict(test)\n",
    "labelencoder_n.inverse_transform(y_pred.argmax(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
